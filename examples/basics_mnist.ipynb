{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f7bf07b9-d489-4484-acb9-175cb740dc60",
   "metadata": {},
   "source": [
    "# Mnist tutorial\n",
    "\n",
    "This notebook introduces the basics of usage of our library.\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a0eebdf-6082-4d00-aa14-b42953217a93",
   "metadata": {},
   "source": [
    "The library is based on tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91c2965e-0375-4966-bc55-776204af9d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9356cd9b-6f79-45f1-8f2e-c46a526c4ae7",
   "metadata": {},
   "source": [
    "### lip-dp dependencies\n",
    "\n",
    "The need a model `DP_Sequential` that handles the noisification of gradients. It is composed `layers` and trained with a loss found in `loss`. The model is initialized with the convenience function `DPParameters`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e5d58f8-386c-44c7-8c5d-e5b69b5be231",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deel.lipdp import layers\n",
    "from deel.lipdp import losses\n",
    "from deel.lipdp.model import DP_Sequential\n",
    "from deel.lipdp.model import DPParameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3a247cd3-48d6-4854-92df-01420d3bea80",
   "metadata": {},
   "source": [
    "The `DP_Accountant` callback keeps track of $(\\epsilon,\\delta)$-DP values epoch after epoch. In practice we may be interested in reaching the maximum val_accuracy under privacy constraint $\\epsilon$: the convenience function `get_max_epochs` exactly does that by performing a dichotomy search over the number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "950c5c56-4b34-4653-aaf3-7d97acc1f5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deel.lipdp.model import DP_Accountant\n",
    "from deel.lipdp.sensitivity import get_max_epochs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "893d3078-5166-428c-9cb1-d29ec1f05d71",
   "metadata": {},
   "source": [
    "The framework requires a control of the maximum norm of inputs. This can be ensured with input clipping for example: `bound_clip_value`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f395c9fc-b67d-4fd2-be4b-b1c43221ebcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deel.lipdp.pipeline import bound_clip_value\n",
    "from deel.lipdp.pipeline import load_and_prepare_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e54a79db-24b4-4dae-b684-170fa743bc5d",
   "metadata": {},
   "source": [
    "## Setup DP Lipschitz model\n",
    "\n",
    "Here we apply the \"global\" strategy, with a noise multiplier $2.5$. Note that for Mnist the dataset size is $N=60,000$, and it is recommended that $\\delta<\\frac{1}{N}$. So we propose a value of $\\delta=10^{-5}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f79ea3b0-33a6-401c-a3a3-e314939fd269",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_parameters = DPParameters(\n",
    "    noisify_strategy=\"global\",\n",
    "    noise_multiplier=2.0,\n",
    "    delta=1e-5,\n",
    ")\n",
    "\n",
    "epsilon_max = 3.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6482128c-ac2e-4cdd-9bbd-6d3172c292b1",
   "metadata": {},
   "source": [
    "### Loading the data\n",
    "\n",
    "We clip the elementwise input upper-bound to $20.0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8ed0fc4-4655-4bad-a6ac-8697cd5bc7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 16:00:31.206597: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-24 16:00:31.742417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 47066 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:03:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# data loader return dataset_metadata which allows to\n",
    "# know the informations required for privacy accounting\n",
    "# (dataset size, number of samples, max input bound...)\n",
    "input_upper_bound = 20.0\n",
    "ds_train, ds_test, dataset_metadata = load_and_prepare_data(\n",
    "    \"mnist\",\n",
    "    batch_size=1000,\n",
    "    drop_remainder=True,  # accounting assumes fixed batch size\n",
    "    bound_fct=bound_clip_value(  # other strategies are possible, like normalization.\n",
    "        input_upper_bound\n",
    "    ),  # clipping preprocessing allows to control input bound\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb356c04-a836-4f49-93d7-7e0cc4c12b1d",
   "metadata": {},
   "source": [
    "### Build the DP model\n",
    "\n",
    "We imitate the interface of Keras. We use common layers found in deel-lip, which a wrapper that handles the bound propagation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30cf44ed-653b-4eaa-8ed9-26e4815db511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct DP_Sequential\n",
    "model = DP_Sequential(\n",
    "    # works like usual sequential but requires DP layers\n",
    "    layers=[\n",
    "        # BoundedInput works like Input, but performs input clipping to guarantee input bound\n",
    "        layers.DP_BoundedInput(\n",
    "            input_shape=dataset_metadata.input_shape, upper_bound=input_upper_bound\n",
    "        ),\n",
    "        layers.DP_QuickSpectralConv2D( # Reshaped Kernel Orthogonalization (RKO) convolution.\n",
    "            filters=32,\n",
    "            kernel_size=3,\n",
    "            kernel_initializer=\"orthogonal\",\n",
    "            strides=1,\n",
    "            use_bias=False,  # No biases since the framework handles a single tf.Variable per layer.\n",
    "        ),\n",
    "        layers.DP_GroupSort(2),  # GNP activation function.\n",
    "        layers.DP_ScaledL2NormPooling2D(pool_size=2, strides=2),  # GNP pooling.\n",
    "        layers.DP_QuickSpectralConv2D( # Reshaped Kernel Orthogonalization (RKO) convolution.\n",
    "            filters=64,\n",
    "            kernel_size=3,\n",
    "            kernel_initializer=\"orthogonal\",\n",
    "            strides=1,\n",
    "            use_bias=False,  # No biases since the framework handles a single tf.Variable per layer.\n",
    "        ),\n",
    "        layers.DP_GroupSort(2),  # GNP activation function.\n",
    "        layers.DP_ScaledL2NormPooling2D(pool_size=2, strides=2),  # GNP pooling.\n",
    "        \n",
    "        layers.DP_Flatten(),   # Convert features maps to flat vector.\n",
    "        \n",
    "        layers.DP_QuickSpectralDense(512),  # GNP layer with orthogonal weight matrix.\n",
    "        layers.DP_GroupSort(2),\n",
    "        layers.DP_QuickSpectralDense(dataset_metadata.nb_classes),\n",
    "    ],\n",
    "    dp_parameters=dp_parameters,\n",
    "    dataset_metadata=dataset_metadata,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "09777811",
   "metadata": {},
   "source": [
    "We compile the model with:\n",
    "* any first order optimizer (e.g SGD). No adaptation or special optimizer is needed.\n",
    "* a loss with known Lipschitz constant, e.g Categorical Cross-entropy with temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efd97e75-34f0-49fa-ad2c-1816247f1611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dp__sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dp__bounded_input (DP_Bound  (None, 28, 28, 1)        0         \n",
      " edInput)                                                        \n",
      "                                                                 \n",
      " dp__quick_spectral_conv2d (  (None, 26, 26, 32)       288       \n",
      " DP_QuickSpectralConv2D)                                         \n",
      "                                                                 \n",
      " dp__group_sort (DP_GroupSor  (None, 26, 26, 32)       0         \n",
      " t)                                                              \n",
      "                                                                 \n",
      " dp__scaled_l2_norm_pooling2  (None, 13, 13, 32)       0         \n",
      " d (DP_ScaledL2NormPooling2D                                     \n",
      " )                                                               \n",
      "                                                                 \n",
      " dp__quick_spectral_conv2d_1  (None, 11, 11, 64)       18432     \n",
      "  (DP_QuickSpectralConv2D)                                       \n",
      "                                                                 \n",
      " dp__group_sort_1 (DP_GroupS  (None, 11, 11, 64)       0         \n",
      " ort)                                                            \n",
      "                                                                 \n",
      " dp__scaled_l2_norm_pooling2  (None, 5, 5, 64)         0         \n",
      " d_1 (DP_ScaledL2NormPooling                                     \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dp__flatten (DP_Flatten)    (None, 1600)              0         \n",
      "                                                                 \n",
      " dp__quick_spectral_dense (D  (None, 512)              819200    \n",
      " P_QuickSpectralDense)                                           \n",
      "                                                                 \n",
      " dp__group_sort_2 (DP_GroupS  (None, 512)              0         \n",
      " ort)                                                            \n",
      "                                                                 \n",
      " dp__quick_spectral_dense_1   (None, 10)               5120      \n",
      " (DP_QuickSpectralDense)                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 843,040\n",
      "Trainable params: 843,040\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    # Compile model using DP loss\n",
    "    loss=losses.DP_TauCategoricalCrossentropy(18.0),\n",
    "    # this method is compatible with any first order optimizer\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=2e-4, momentum=0.9),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "28ae2da5-ed40-4131-8721-73bbc73fa68d",
   "metadata": {},
   "source": [
    "Note that the model contains $843$K parameters. Without gradient clipping these architectures can be trained with batch sizes as big as $1000$ on a standard GPU.\n",
    "\n",
    "Then, we compute the number of epochs. The maximum value of epsilon will depends on dp_parameters and the number of epochs. In order to control epsilon, we compute the adequate number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd611afd-be30-4bd3-b658-48d1961247aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch bounds = (0, 512.0) and epsilon = 7.994426666195571 at epoch 512.0\n",
      "epoch bounds = (0, 256.0) and epsilon = 5.34128917907949 at epoch 256.0\n",
      "epoch bounds = (0, 128.0) and epsilon = 3.631964622805248 at epoch 128.0\n",
      "epoch bounds = (64.0, 128.0) and epsilon = 2.4829841192119444 at epoch 64.0\n",
      "epoch bounds = (64.0, 96.0) and epsilon = 3.089635897639078 at epoch 96.0\n",
      "epoch bounds = (80.0, 96.0) and epsilon = 2.796528753679695 at epoch 80.0\n",
      "epoch bounds = (88.0, 96.0) and epsilon = 2.952713799856404 at epoch 88.0\n",
      "epoch bounds = (88.0, 92.0) and epsilon = 3.0216241846349847 at epoch 92.0\n",
      "epoch bounds = (90.0, 92.0) and epsilon = 2.987618328313939 at epoch 90.0\n",
      "epoch bounds = (90.0, 91.0) and epsilon = 3.0046212568846444 at epoch 91.0\n"
     ]
    }
   ],
   "source": [
    "num_epochs = get_max_epochs(epsilon_max, model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "53e94244",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "The model can be trained, and the DP Accountant will automatically track the privacy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ddcb192-547e-400e-87bb-2d4246185c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 16:00:36.621954: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8300\n",
      "2023-05-24 16:00:37.363789: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - ETA: 0s - loss: 0.2020 - accuracy: 0.2324\n",
      " (0.3227333785403041, 1e-05)-DP guarantees for epoch 1 \n",
      "\n",
      "60/60 [==============================] - 5s 38ms/step - loss: 0.2020 - accuracy: 0.2324 - val_loss: 0.1712 - val_accuracy: 0.3147\n",
      "Epoch 2/91\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.1607 - accuracy: 0.3958\n",
      " (0.41135036253440604, 1e-05)-DP guarantees for epoch 2 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.1604 - accuracy: 0.3992 - val_loss: 0.1486 - val_accuracy: 0.5122\n",
      "Epoch 3/91\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1426 - accuracy: 0.5510\n",
      " (0.4972854400421322, 1e-05)-DP guarantees for epoch 3 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.1426 - accuracy: 0.5510 - val_loss: 0.1334 - val_accuracy: 0.6108\n",
      "Epoch 4/91\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1291 - accuracy: 0.6333\n",
      " (0.5737399623472044, 1e-05)-DP guarantees for epoch 4 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.1291 - accuracy: 0.6333 - val_loss: 0.1213 - val_accuracy: 0.6784\n",
      "Epoch 5/91\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1182 - accuracy: 0.6883\n",
      " (0.6418194146435952, 1e-05)-DP guarantees for epoch 5 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.1182 - accuracy: 0.6883 - val_loss: 0.1109 - val_accuracy: 0.7180\n",
      "Epoch 6/91\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.1088 - accuracy: 0.7247\n",
      " (0.7042008802236781, 1e-05)-DP guarantees for epoch 6 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.1087 - accuracy: 0.7247 - val_loss: 0.1024 - val_accuracy: 0.7527\n",
      "Epoch 7/91\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.1012 - accuracy: 0.7488\n",
      " (0.7616059152520757, 1e-05)-DP guarantees for epoch 7 \n",
      "\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 0.1012 - accuracy: 0.7488 - val_loss: 0.0955 - val_accuracy: 0.7698\n",
      "Epoch 8/91\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0948 - accuracy: 0.7644\n",
      " (0.8155744676428971, 1e-05)-DP guarantees for epoch 8 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.0948 - accuracy: 0.7644 - val_loss: 0.0899 - val_accuracy: 0.7815\n",
      "Epoch 9/91\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0896 - accuracy: 0.7785\n",
      " (0.8666021691681208, 1e-05)-DP guarantees for epoch 9 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.0896 - accuracy: 0.7785 - val_loss: 0.0848 - val_accuracy: 0.7936\n",
      "Epoch 10/91\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0849 - accuracy: 0.7868\n",
      " (0.9152742048884784, 1e-05)-DP guarantees for epoch 10 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.0849 - accuracy: 0.7868 - val_loss: 0.0804 - val_accuracy: 0.8003\n",
      "Epoch 11/91\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.0810 - accuracy: 0.7967\n",
      " (0.9617965624530973, 1e-05)-DP guarantees for epoch 11 \n",
      "\n",
      "60/60 [==============================] - 2s 30ms/step - loss: 0.0809 - accuracy: 0.7975 - val_loss: 0.0769 - val_accuracy: 0.8109\n",
      "Epoch 12/91\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0774 - accuracy: 0.8060\n",
      " (1.0059716506359193, 1e-05)-DP guarantees for epoch 12 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.0774 - accuracy: 0.8060 - val_loss: 0.0733 - val_accuracy: 0.8179\n",
      "Epoch 13/91\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0740 - accuracy: 0.8131\n",
      " (1.049398006635733, 1e-05)-DP guarantees for epoch 13 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.0740 - accuracy: 0.8131 - val_loss: 0.0704 - val_accuracy: 0.8269\n",
      "Epoch 14/91\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0713 - accuracy: 0.8216\n",
      " (1.090263192229449, 1e-05)-DP guarantees for epoch 14 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.0713 - accuracy: 0.8216 - val_loss: 0.0677 - val_accuracy: 0.8309\n",
      "Epoch 15/91\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0689 - accuracy: 0.8240\n",
      " (1.131126828240101, 1e-05)-DP guarantees for epoch 15 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.0689 - accuracy: 0.8240 - val_loss: 0.0656 - val_accuracy: 0.8355\n",
      "Epoch 16/91\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.0669 - accuracy: 0.8293\n",
      " (1.169340908770284, 1e-05)-DP guarantees for epoch 16 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.0668 - accuracy: 0.8296 - val_loss: 0.0635 - val_accuracy: 0.8398\n",
      "Epoch 17/91\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.0647 - accuracy: 0.8333\n",
      " (1.2074292910030167, 1e-05)-DP guarantees for epoch 17 \n",
      "\n",
      "60/60 [==============================] - 2s 29ms/step - loss: 0.0646 - accuracy: 0.8335 - val_loss: 0.0615 - val_accuracy: 0.8437\n",
      "Epoch 18/91\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.0630 - accuracy: 0.8366\n",
      " (1.2447047350704166, 1e-05)-DP guarantees for epoch 18 \n",
      "\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 0.0629 - accuracy: 0.8367 - val_loss: 0.0598 - val_accuracy: 0.8468\n",
      "Epoch 19/91\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0612 - accuracy: 0.8399\n",
      " (1.2800495944157277, 1e-05)-DP guarantees for epoch 19 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.0612 - accuracy: 0.8399 - val_loss: 0.0582 - val_accuracy: 0.8508\n",
      "Epoch 20/91\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0598 - accuracy: 0.8428\n",
      " (1.3153944538284068, 1e-05)-DP guarantees for epoch 20 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.0598 - accuracy: 0.8428 - val_loss: 0.0569 - val_accuracy: 0.8563\n",
      "Epoch 21/91\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.0584 - accuracy: 0.8468\n",
      " (1.3507368078845663, 1e-05)-DP guarantees for epoch 21 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.0584 - accuracy: 0.8466 - val_loss: 0.0557 - val_accuracy: 0.8572\n",
      "Epoch 22/91\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0572 - accuracy: 0.8509\n",
      " (1.383564204783113, 1e-05)-DP guarantees for epoch 22 \n",
      "\n",
      "60/60 [==============================] - 2s 30ms/step - loss: 0.0572 - accuracy: 0.8509 - val_loss: 0.0546 - val_accuracy: 0.8610\n",
      "Epoch 23/91\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.0561 - accuracy: 0.8519\n",
      " (1.4161979427317832, 1e-05)-DP guarantees for epoch 23 \n",
      "\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 0.0562 - accuracy: 0.8518 - val_loss: 0.0537 - val_accuracy: 0.8619\n",
      "Epoch 24/91\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0552 - accuracy: 0.8547\n",
      " (1.448831680775656, 1e-05)-DP guarantees for epoch 24 \n",
      "\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 0.0552 - accuracy: 0.8547 - val_loss: 0.0525 - val_accuracy: 0.8657\n",
      "Epoch 25/91\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0541 - accuracy: 0.8575\n",
      " (1.4814654188092617, 1e-05)-DP guarantees for epoch 25 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.0541 - accuracy: 0.8576 - val_loss: 0.0516 - val_accuracy: 0.8675\n",
      "Epoch 26/91\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0531 - accuracy: 0.8578\n",
      " (1.512526290723161, 1e-05)-DP guarantees for epoch 26 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.0531 - accuracy: 0.8578 - val_loss: 0.0506 - val_accuracy: 0.8691\n",
      "Epoch 27/91\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0522 - accuracy: 0.8605\n",
      " (1.5424804710143858, 1e-05)-DP guarantees for epoch 27 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.0522 - accuracy: 0.8605 - val_loss: 0.0497 - val_accuracy: 0.8709\n",
      "Epoch 28/91\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.0512 - accuracy: 0.8624\n",
      " (1.5724346510360574, 1e-05)-DP guarantees for epoch 28 \n",
      "\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 0.0512 - accuracy: 0.8626 - val_loss: 0.0488 - val_accuracy: 0.8730\n",
      "Epoch 29/91\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0503 - accuracy: 0.8650\n",
      " (1.6023888317992228, 1e-05)-DP guarantees for epoch 29 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.0503 - accuracy: 0.8653 - val_loss: 0.0479 - val_accuracy: 0.8752\n",
      "Epoch 30/91\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0495 - accuracy: 0.8665\n",
      " (1.632343011263517, 1e-05)-DP guarantees for epoch 30 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.0495 - accuracy: 0.8667 - val_loss: 0.0471 - val_accuracy: 0.8749\n",
      "Epoch 31/91\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.0488 - accuracy: 0.8684\n",
      " (1.6622962394525178, 1e-05)-DP guarantees for epoch 31 \n",
      "\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 0.0487 - accuracy: 0.8686 - val_loss: 0.0463 - val_accuracy: 0.8779\n",
      "Epoch 32/91\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0480 - accuracy: 0.8697\n",
      " (1.689965116494089, 1e-05)-DP guarantees for epoch 32 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.0480 - accuracy: 0.8697 - val_loss: 0.0457 - val_accuracy: 0.8777\n",
      "Epoch 33/91\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.0475 - accuracy: 0.8700\n",
      " (1.7172705001520499, 1e-05)-DP guarantees for epoch 33 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.0475 - accuracy: 0.8704 - val_loss: 0.0452 - val_accuracy: 0.8790\n",
      "Epoch 34/91\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.0469 - accuracy: 0.8736\n",
      " (1.7445758842338837, 1e-05)-DP guarantees for epoch 34 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.0468 - accuracy: 0.8738 - val_loss: 0.0446 - val_accuracy: 0.8806\n",
      "Epoch 35/91\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0463 - accuracy: 0.8754\n",
      " (1.7718812676250233, 1e-05)-DP guarantees for epoch 35 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.0462 - accuracy: 0.8756 - val_loss: 0.0441 - val_accuracy: 0.8825\n",
      "Epoch 36/91\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0456 - accuracy: 0.8763\n",
      " (1.799186650959813, 1e-05)-DP guarantees for epoch 36 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.0456 - accuracy: 0.8763 - val_loss: 0.0434 - val_accuracy: 0.8831\n",
      "Epoch 37/91\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.0450 - accuracy: 0.8771\n",
      " (1.8264920346090618, 1e-05)-DP guarantees for epoch 37 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.0450 - accuracy: 0.8773 - val_loss: 0.0429 - val_accuracy: 0.8846\n",
      "Epoch 38/91\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.0444 - accuracy: 0.8786\n",
      " (1.8537974184156425, 1e-05)-DP guarantees for epoch 38 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.0444 - accuracy: 0.8786 - val_loss: 0.0423 - val_accuracy: 0.8855\n",
      "Epoch 39/91\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.0439 - accuracy: 0.8800\n",
      " (1.8807666749981604, 1e-05)-DP guarantees for epoch 39 \n",
      "\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 0.0439 - accuracy: 0.8802 - val_loss: 0.0419 - val_accuracy: 0.8863\n",
      "Epoch 40/91\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.0435 - accuracy: 0.8803\n",
      " (1.9054738700393052, 1e-05)-DP guarantees for epoch 40 \n",
      "\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 0.0435 - accuracy: 0.8804 - val_loss: 0.0415 - val_accuracy: 0.8858\n",
      "Epoch 41/91\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0430 - accuracy: 0.8816\n",
      " (1.9301604511513608, 1e-05)-DP guarantees for epoch 41 \n",
      "\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 0.0430 - accuracy: 0.8816 - val_loss: 0.0410 - val_accuracy: 0.8884\n",
      "Epoch 42/91\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0425 - accuracy: 0.8824\n",
      " (1.9548470320035656, 1e-05)-DP guarantees for epoch 42 \n",
      "\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 0.0425 - accuracy: 0.8824 - val_loss: 0.0405 - val_accuracy: 0.8890\n",
      "Epoch 43/91\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0421 - accuracy: 0.8837\n",
      " (1.979533612594768, 1e-05)-DP guarantees for epoch 43 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.0421 - accuracy: 0.8837 - val_loss: 0.0403 - val_accuracy: 0.8890\n",
      "Epoch 44/91\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0418 - accuracy: 0.8856\n",
      " (2.0042201936126345, 1e-05)-DP guarantees for epoch 44 \n",
      "\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 0.0418 - accuracy: 0.8856 - val_loss: 0.0399 - val_accuracy: 0.8908\n",
      "Epoch 45/91\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.0414 - accuracy: 0.8858\n",
      " (2.0289067746857206, 1e-05)-DP guarantees for epoch 45 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.0414 - accuracy: 0.8856 - val_loss: 0.0393 - val_accuracy: 0.8926\n",
      "Epoch 46/91\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0408 - accuracy: 0.8872\n",
      " (2.053593355232055, 1e-05)-DP guarantees for epoch 46 \n",
      "\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 0.0408 - accuracy: 0.8872 - val_loss: 0.0388 - val_accuracy: 0.8951\n",
      "Epoch 47/91\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.0405 - accuracy: 0.8882\n",
      " (2.078279935996221, 1e-05)-DP guarantees for epoch 47 \n",
      "\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 0.0404 - accuracy: 0.8887 - val_loss: 0.0385 - val_accuracy: 0.8959\n",
      "Epoch 48/91\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0400 - accuracy: 0.8882\n",
      " (2.1029665168498504, 1e-05)-DP guarantees for epoch 48 \n",
      "\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 0.0400 - accuracy: 0.8882 - val_loss: 0.0381 - val_accuracy: 0.8952\n",
      "Epoch 49/91\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.0397 - accuracy: 0.8890\n",
      " (2.127653097450219, 1e-05)-DP guarantees for epoch 49 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.0398 - accuracy: 0.8888 - val_loss: 0.0379 - val_accuracy: 0.8943\n",
      "Epoch 50/91\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.0396 - accuracy: 0.8887\n",
      " (2.151531383398666, 1e-05)-DP guarantees for epoch 50 \n",
      "\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 0.0395 - accuracy: 0.8889 - val_loss: 0.0375 - val_accuracy: 0.8946\n",
      "Epoch 51/91\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.0391 - accuracy: 0.8893\n",
      " (2.1736284198821467, 1e-05)-DP guarantees for epoch 51 \n",
      "\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 0.0391 - accuracy: 0.8895 - val_loss: 0.0372 - val_accuracy: 0.8968\n",
      "Epoch 52/91\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.0387 - accuracy: 0.8908\n",
      " (2.195725456202997, 1e-05)-DP guarantees for epoch 52 \n",
      "\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 0.0387 - accuracy: 0.8908 - val_loss: 0.0368 - val_accuracy: 0.8967\n",
      "Epoch 53/91\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0385 - accuracy: 0.8905\n",
      " (2.217822492103547, 1e-05)-DP guarantees for epoch 53 \n",
      "\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 0.0385 - accuracy: 0.8905 - val_loss: 0.0366 - val_accuracy: 0.8991\n",
      "Epoch 54/91\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0382 - accuracy: 0.8913\n",
      " (2.2399195284840734, 1e-05)-DP guarantees for epoch 54 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.0382 - accuracy: 0.8913 - val_loss: 0.0365 - val_accuracy: 0.8992\n",
      "Epoch 55/91\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.0380 - accuracy: 0.8924\n",
      " (2.2620165646623547, 1e-05)-DP guarantees for epoch 55 \n",
      "\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 0.0380 - accuracy: 0.8921 - val_loss: 0.0362 - val_accuracy: 0.8994\n",
      "Epoch 56/91\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0377 - accuracy: 0.8925\n",
      " (2.2841136015562187, 1e-05)-DP guarantees for epoch 56 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.0377 - accuracy: 0.8925 - val_loss: 0.0358 - val_accuracy: 0.8999\n",
      "Epoch 57/91\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0374 - accuracy: 0.8930\n",
      " (2.3062106367493893, 1e-05)-DP guarantees for epoch 57 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.0374 - accuracy: 0.8930 - val_loss: 0.0356 - val_accuracy: 0.9004\n",
      "Epoch 58/91\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.0371 - accuracy: 0.8938\n",
      " (2.3283076739544244, 1e-05)-DP guarantees for epoch 58 \n",
      "\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 0.0372 - accuracy: 0.8939 - val_loss: 0.0354 - val_accuracy: 0.9010\n",
      "Epoch 59/91\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0369 - accuracy: 0.8951\n",
      " (2.3504047095381226, 1e-05)-DP guarantees for epoch 59 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.0369 - accuracy: 0.8951 - val_loss: 0.0351 - val_accuracy: 0.9010\n",
      "Epoch 60/91\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0365 - accuracy: 0.8963\n",
      " (2.3725017457248683, 1e-05)-DP guarantees for epoch 60 \n",
      "\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 0.0365 - accuracy: 0.8963 - val_loss: 0.0347 - val_accuracy: 0.9037\n",
      "Epoch 61/91\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0363 - accuracy: 0.8968\n",
      " (2.3945987822094885, 1e-05)-DP guarantees for epoch 61 \n",
      "\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 0.0363 - accuracy: 0.8968 - val_loss: 0.0346 - val_accuracy: 0.9024\n",
      "Epoch 62/91\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.0360 - accuracy: 0.8979\n",
      " (2.4166958179233653, 1e-05)-DP guarantees for epoch 62 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.0360 - accuracy: 0.8981 - val_loss: 0.0343 - val_accuracy: 0.9041\n",
      "Epoch 63/91\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.0358 - accuracy: 0.8986\n",
      " (2.438792853624178, 1e-05)-DP guarantees for epoch 63 \n",
      "\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 0.0358 - accuracy: 0.8987 - val_loss: 0.0340 - val_accuracy: 0.9068\n",
      "Epoch 64/91\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.0355 - accuracy: 0.8995\n",
      " (2.4608898896847116, 1e-05)-DP guarantees for epoch 64 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.0356 - accuracy: 0.8992 - val_loss: 0.0338 - val_accuracy: 0.9072\n",
      "Epoch 65/91\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.0352 - accuracy: 0.9005\n",
      " (2.4829841192119444, 1e-05)-DP guarantees for epoch 65 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.0353 - accuracy: 0.9000 - val_loss: 0.0336 - val_accuracy: 0.9059\n",
      "Epoch 66/91\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0351 - accuracy: 0.8996\n",
      " (2.5034880893370737, 1e-05)-DP guarantees for epoch 66 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.0351 - accuracy: 0.8996 - val_loss: 0.0334 - val_accuracy: 0.9070\n",
      "Epoch 67/91\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0350 - accuracy: 0.9003\n",
      " (2.523024133549594, 1e-05)-DP guarantees for epoch 67 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.0349 - accuracy: 0.9003 - val_loss: 0.0333 - val_accuracy: 0.9069\n",
      "Epoch 68/91\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0348 - accuracy: 0.9005\n",
      " (2.542560178527111, 1e-05)-DP guarantees for epoch 68 \n",
      "\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 0.0348 - accuracy: 0.9005 - val_loss: 0.0332 - val_accuracy: 0.9071\n",
      "Epoch 69/91\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.0346 - accuracy: 0.9006\n",
      " (2.5620962223364145, 1e-05)-DP guarantees for epoch 69 \n",
      "\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 0.0347 - accuracy: 0.9007 - val_loss: 0.0329 - val_accuracy: 0.9081\n",
      "Epoch 70/91\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0345 - accuracy: 0.9015\n",
      " (2.5816322672410785, 1e-05)-DP guarantees for epoch 70 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.0345 - accuracy: 0.9014 - val_loss: 0.0327 - val_accuracy: 0.9069\n",
      "Epoch 71/91\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.0343 - accuracy: 0.9017\n",
      " (2.601168310806795, 1e-05)-DP guarantees for epoch 71 \n",
      "\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 0.0343 - accuracy: 0.9019 - val_loss: 0.0326 - val_accuracy: 0.9090\n",
      "Epoch 72/91\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.0342 - accuracy: 0.9021\n",
      " (2.620704354996593, 1e-05)-DP guarantees for epoch 72 \n",
      "\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 0.0342 - accuracy: 0.9022 - val_loss: 0.0324 - val_accuracy: 0.9089\n",
      "Epoch 73/91\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.0340 - accuracy: 0.9018\n",
      " (2.640240400625916, 1e-05)-DP guarantees for epoch 73 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.0339 - accuracy: 0.9020 - val_loss: 0.0322 - val_accuracy: 0.9096\n",
      "Epoch 74/91\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.0339 - accuracy: 0.9018\n",
      " (2.659776444789028, 1e-05)-DP guarantees for epoch 74 \n",
      "\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 0.0338 - accuracy: 0.9022 - val_loss: 0.0320 - val_accuracy: 0.9103\n",
      "Epoch 75/91\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0335 - accuracy: 0.9024\n",
      " (2.679312488654814, 1e-05)-DP guarantees for epoch 75 \n",
      "\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 0.0335 - accuracy: 0.9024 - val_loss: 0.0318 - val_accuracy: 0.9088\n",
      "Epoch 76/91\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0333 - accuracy: 0.9025\n",
      " (2.69884853278786, 1e-05)-DP guarantees for epoch 76 \n",
      "\n",
      "60/60 [==============================] - 2s 29ms/step - loss: 0.0333 - accuracy: 0.9023 - val_loss: 0.0315 - val_accuracy: 0.9098\n",
      "Epoch 77/91\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0332 - accuracy: 0.9033\n",
      " (2.7183845763895516, 1e-05)-DP guarantees for epoch 77 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.0332 - accuracy: 0.9033 - val_loss: 0.0314 - val_accuracy: 0.9125\n",
      "Epoch 78/91\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.0330 - accuracy: 0.9046\n",
      " (2.737920620600221, 1e-05)-DP guarantees for epoch 78 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.0330 - accuracy: 0.9048 - val_loss: 0.0313 - val_accuracy: 0.9119\n",
      "Epoch 79/91\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0328 - accuracy: 0.9053\n",
      " (2.7574566653298858, 1e-05)-DP guarantees for epoch 79 \n",
      "\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 0.0328 - accuracy: 0.9053 - val_loss: 0.0311 - val_accuracy: 0.9115\n",
      "Epoch 80/91\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.0328 - accuracy: 0.9052\n",
      " (2.7769927101097007, 1e-05)-DP guarantees for epoch 80 \n",
      "\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 0.0327 - accuracy: 0.9056 - val_loss: 0.0310 - val_accuracy: 0.9118\n",
      "Epoch 81/91\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0325 - accuracy: 0.9056\n",
      " (2.796528753679695, 1e-05)-DP guarantees for epoch 81 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.0325 - accuracy: 0.9056 - val_loss: 0.0308 - val_accuracy: 0.9114\n",
      "Epoch 82/91\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0324 - accuracy: 0.9057\n",
      " (2.816064798903292, 1e-05)-DP guarantees for epoch 82 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.0324 - accuracy: 0.9057 - val_loss: 0.0307 - val_accuracy: 0.9114\n",
      "Epoch 83/91\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.0323 - accuracy: 0.9053\n",
      " (2.8356008431856474, 1e-05)-DP guarantees for epoch 83 \n",
      "\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 0.0322 - accuracy: 0.9057 - val_loss: 0.0305 - val_accuracy: 0.9117\n",
      "Epoch 84/91\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0320 - accuracy: 0.9063\n",
      " (2.8551368864333964, 1e-05)-DP guarantees for epoch 84 \n",
      "\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 0.0320 - accuracy: 0.9063 - val_loss: 0.0303 - val_accuracy: 0.9117\n",
      "Epoch 85/91\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0318 - accuracy: 0.9064\n",
      " (2.8746729305801413, 1e-05)-DP guarantees for epoch 85 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.0318 - accuracy: 0.9064 - val_loss: 0.0302 - val_accuracy: 0.9121\n",
      "Epoch 86/91\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0317 - accuracy: 0.9074\n",
      " (2.894208975473722, 1e-05)-DP guarantees for epoch 86 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.0316 - accuracy: 0.9076 - val_loss: 0.0299 - val_accuracy: 0.9132\n",
      "Epoch 87/91\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.0314 - accuracy: 0.9078\n",
      " (2.9137450193835823, 1e-05)-DP guarantees for epoch 87 \n",
      "\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 0.0314 - accuracy: 0.9076 - val_loss: 0.0298 - val_accuracy: 0.9123\n",
      "Epoch 88/91\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0313 - accuracy: 0.9086\n",
      " (2.9332810632263646, 1e-05)-DP guarantees for epoch 88 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.0313 - accuracy: 0.9086 - val_loss: 0.0299 - val_accuracy: 0.9133\n",
      "Epoch 89/91\n",
      "59/60 [============================>.] - ETA: 0s - loss: 0.0313 - accuracy: 0.9087\n",
      " (2.952713799856404, 1e-05)-DP guarantees for epoch 89 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.0313 - accuracy: 0.9087 - val_loss: 0.0298 - val_accuracy: 0.9140\n",
      "Epoch 90/91\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.0312 - accuracy: 0.9097\n",
      " (2.970615400210975, 1e-05)-DP guarantees for epoch 90 \n",
      "\n",
      "60/60 [==============================] - 2s 28ms/step - loss: 0.0312 - accuracy: 0.9097 - val_loss: 0.0298 - val_accuracy: 0.9127\n",
      "Epoch 91/91\n",
      "58/60 [============================>.] - ETA: 0s - loss: 0.0312 - accuracy: 0.9091\n",
      " (2.987618328313939, 1e-05)-DP guarantees for epoch 91 \n",
      "\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 0.0312 - accuracy: 0.9093 - val_loss: 0.0297 - val_accuracy: 0.9132\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(\n",
    "    ds_train,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=ds_test,\n",
    "    callbacks=[\n",
    "        # accounting is done thanks to a callback\n",
    "        DP_Accountant(log_fn=\"logging\"),  # wandb.log also available.\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cbeee4-c204-454f-8f6f-20273b0169b7",
   "metadata": {},
   "source": [
    "The model can be further improved by tuning various hyper-parameters, by adding layers (see `advanced_cifar10.ipynb` tutorial). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedc70ab-ccd5-4239-9d62-416d680af324",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
