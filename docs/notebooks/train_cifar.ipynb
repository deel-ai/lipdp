{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR CLASSIFICATION"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import deel.lipdp.layers as DP_layers\n",
    "import deel.lipdp.losses as DP_losses\n",
    "from deel.lipdp.pipeline import bound_clip_value\n",
    "from deel.lipdp.pipeline import load_and_prepare_data\n",
    "from deel.lipdp.sensitivity import get_max_epochs\n",
    "from deel.lipdp.model import DP_Accountant\n",
    "from deel.lipdp.model import DP_Sequential\n",
    "from deel.lipdp.model import DPParameters\n",
    "from deel.lipdp.model import AdaptiveLossGradientClipping"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data :\n",
    "\n",
    "It is important to import the data with the right DP parameters to account properly for the privacy guarantees of the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment = True \n",
    "\n",
    "if augment : \n",
    "    augmentations = [\n",
    "        tf.image.flip_left_right,\n",
    "    ]\n",
    "else : \n",
    "    augmentations = None \n",
    "    \n",
    "ds_train, ds_test, dataset_metadata = load_and_prepare_data(\n",
    "    \"cifar10\",\n",
    "    batch_size=2048,\n",
    "    colorspace=\"HSV\",\n",
    "    augmentations=augmentations,\n",
    "    drop_remainder=True,  # accounting assumes fixed batch size\n",
    "    bound_fct=bound_clip_value(\n",
    "        15.0\n",
    "    ),  # clipping preprocessing allows to control input bound\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please pay attention to the fact that the effective batch size in memory will be batch_size $\\times$ len(augmentations).\n",
    "\n",
    "Fortunately, the backpropagation's computation time on our framework is less sensitive to the batch size than for other frameworks : \n",
    "\n",
    "<img src=\"ressources/all_speed_curves.png\" alt=\"Speed curves with concurrent frameworks\" width=\"800\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaring the DP parameters :\n",
    "\n",
    "We also need to declare explicitly the parameters of the DP training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_parameters = DPParameters(\n",
    "    noisify_strategy=\"global\",\n",
    "    noise_multiplier=1.0,\n",
    "    delta=1e-5,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the model :\n",
    "\n",
    "We use a simple convolutive network to classify on the MNIST dataset. We add a loss gradient clipping layer at the end of our network for more tightness on our gradient's upper bound. Therefore allowing for better results with one less hyperparameter to tune for dynamically chosen clipping constant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.9/site-packages/deel/lip/model.py:74: UserWarning: Sequential model contains a layer which is not a 1-Lipschitz layer: dp__bounded_input_13\n",
      "  warn(_msg_not_lip.format(layer.name))\n",
      "/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.9/site-packages/deel/lip/model.py:74: UserWarning: Sequential model contains a layer which is not a 1-Lipschitz layer: dp__clip_gradient_13\n",
      "  warn(_msg_not_lip.format(layer.name))\n"
     ]
    }
   ],
   "source": [
    "layers = [\n",
    "    DP_layers.DP_BoundedInput(\n",
    "        input_shape=dataset_metadata.input_shape,\n",
    "        upper_bound=dataset_metadata.max_norm,\n",
    "    ),\n",
    "    DP_layers.DP_SpectralConv2D(\n",
    "        filters=32, kernel_size=3, use_bias=False, kernel_initializer=\"orthogonal\"\n",
    "    ),\n",
    "    DP_layers.DP_Flatten(),\n",
    "    DP_layers.DP_SpectralDense(\n",
    "        units=512, use_bias=False, kernel_initializer=\"orthogonal\"\n",
    "    ),\n",
    "    DP_layers.DP_GroupSort(2),\n",
    "    DP_layers.DP_SpectralDense(\n",
    "        units=10, use_bias=False, kernel_initializer=\"orthogonal\"\n",
    "    ),\n",
    "    DP_layers.DP_ClipGradient(\n",
    "        epsilon=1, mode=\"dynamic_svt\", patience=5\n",
    "    )\n",
    "]\n",
    "\n",
    "model = DP_Sequential(\n",
    "    layers=layers, dp_parameters=dp_parameters, dataset_metadata=dataset_metadata\n",
    ")\n",
    "\n",
    "loss = DP_losses.DP_TauCategoricalCrossentropy(tau=20.0)\n",
    "\n",
    "# Compatible with any kind of non-private optimizer : \n",
    "opt = tf.keras.optimizers.SGD(learning_rate=1e-2)\n",
    "\n",
    "model.compile(\n",
    "    loss=loss,\n",
    "    optimizer=opt,\n",
    "    metrics=[\"accuracy\"],\n",
    "    run_eagerly=False,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the desired DP guarantees :\n",
    "\n",
    "We compute the budget of epochs needed to yields the DP guarantees that you desire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch bounds = (0, 512.0) and epsilon = 145.43699578143378 at epoch 512.0\n",
      "epoch bounds = (0, 256.0) and epsilon = 78.50396131727922 at epoch 256.0\n",
      "epoch bounds = (0, 128.0) and epsilon = 44.007702875320284 at epoch 128.0\n",
      "epoch bounds = (0, 64.0) and epsilon = 26.759573654340812 at epoch 64.0\n",
      "epoch bounds = (0, 32.0) and epsilon = 17.233876551599256 at epoch 32.0\n",
      "epoch bounds = (0, 16.0) and epsilon = 11.129175323732037 at epoch 16.0\n",
      "epoch bounds = (8.0, 16.0) and epsilon = 7.653461249237745 at epoch 8.0\n",
      "epoch bounds = (8.0, 12.0) and epsilon = 9.391318298430164 at epoch 12.0\n",
      "epoch bounds = (8.0, 10.0) and epsilon = 8.945753193137257 at epoch 10.0\n",
      "epoch bounds = (9.0, 10.0) and epsilon = 7.876243805065025 at epoch 9.0\n"
     ]
    }
   ],
   "source": [
    "num_epochs = get_max_epochs(8.0, model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model : \n",
    "\n",
    "The training process is called through the model.fit attribute. We use the following callbacks : \n",
    "\n",
    "- **DP_Accountant** (log_fn) : accounts for the privacy guarantees after each epoch of training (*log_fn* makes it compatible with W&B logging).\n",
    "- **DP_AdaptiveGradientClipping** (ds_train, patience) : automatically updates the losses's gradient clipping constant every *patience* steps. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On train begin : \n",
      "Initial value is now equal to lipschitz constant of loss:  tf.Tensor(1.4142135, shape=(), dtype=float32)\n",
      "Epoch 1/9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - ETA: 0s - loss: 0.1232 - accuracy: 0.1793\n",
      " (3.520469678118549, 1e-05)-DP guarantees for epoch 1 \n",
      "\n",
      "updated_clip_value :  1.0928657358879175\n",
      "24/24 [==============================] - 8s 266ms/step - loss: 0.1232 - accuracy: 0.1793 - val_loss: 0.1148 - val_accuracy: 0.2158\n",
      "Epoch 2/9\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1116 - accuracy: 0.2409\n",
      " (3.953077748875339, 1e-05)-DP guarantees for epoch 2 \n",
      "\n",
      "24/24 [==============================] - 5s 203ms/step - loss: 0.1116 - accuracy: 0.2409 - val_loss: 0.1043 - val_accuracy: 0.2599\n",
      "Epoch 3/9\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1097 - accuracy: 0.2550\n",
      " (4.38568578363591, 1e-05)-DP guarantees for epoch 3 \n",
      "\n",
      "24/24 [==============================] - 5s 199ms/step - loss: 0.1097 - accuracy: 0.2550 - val_loss: 0.1136 - val_accuracy: 0.2708\n",
      "Epoch 4/9\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1056 - accuracy: 0.2745\n",
      " (4.818293794804343, 1e-05)-DP guarantees for epoch 4 \n",
      "\n",
      "24/24 [==============================] - 5s 203ms/step - loss: 0.1056 - accuracy: 0.2745 - val_loss: 0.1063 - val_accuracy: 0.2599\n",
      "Epoch 5/9\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1035 - accuracy: 0.2871\n",
      " (6.146785094069724, 1e-05)-DP guarantees for epoch 5 \n",
      "\n",
      "24/24 [==============================] - 5s 199ms/step - loss: 0.1035 - accuracy: 0.2871 - val_loss: 0.0988 - val_accuracy: 0.2974\n",
      "Epoch 6/9\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1020 - accuracy: 0.2961\n",
      " (6.579393133892413, 1e-05)-DP guarantees for epoch 6 \n",
      "\n",
      "updated_clip_value :  1.090034477504788\n",
      "24/24 [==============================] - 7s 259ms/step - loss: 0.1020 - accuracy: 0.2961 - val_loss: 0.0988 - val_accuracy: 0.2950\n",
      "Epoch 7/9\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.0991 - accuracy: 0.3066\n",
      " (7.012001173715104, 1e-05)-DP guarantees for epoch 7 \n",
      "\n",
      "24/24 [==============================] - 5s 205ms/step - loss: 0.0991 - accuracy: 0.3066 - val_loss: 0.0944 - val_accuracy: 0.3335\n",
      "Epoch 8/9\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.0981 - accuracy: 0.3136\n",
      " (7.42943319023189, 1e-05)-DP guarantees for epoch 8 \n",
      "\n",
      "24/24 [==============================] - 5s 198ms/step - loss: 0.0981 - accuracy: 0.3136 - val_loss: 0.0975 - val_accuracy: 0.3118\n",
      "Epoch 9/9\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.0969 - accuracy: 0.3212\n",
      " (7.653461249237745, 1e-05)-DP guarantees for epoch 9 \n",
      "\n",
      "24/24 [==============================] - 5s 204ms/step - loss: 0.0969 - accuracy: 0.3212 - val_loss: 0.0960 - val_accuracy: 0.3173\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    DP_Accountant(log_fn=\"logging\"),\n",
    "    AdaptiveLossGradientClipping(\n",
    "        ds_train=ds_train\n",
    "    ),  # DO NOT USE THIS CALLBACK WHEN mode != \"dynamic_svt\"\n",
    "]\n",
    "\n",
    "hist = model.fit(\n",
    "    ds_train,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=ds_test,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lipdp_dev_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
