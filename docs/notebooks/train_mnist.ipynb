{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST CLASSIFICATION"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-06 17:15:20.795797: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-06 17:15:20.889349: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-07-06 17:15:21.597934: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cudnn/11.2-v8.1.0/cuda/lib64:/usr/local/cuda-11.2/lib64\n",
      "2023-07-06 17:15:21.597977: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cudnn/11.2-v8.1.0/cuda/lib64:/usr/local/cuda-11.2/lib64\n",
      "2023-07-06 17:15:21.597982: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import deel.lipdp.layers as DP_layers\n",
    "import deel.lipdp.losses as DP_losses\n",
    "from deel.lipdp.pipeline import bound_clip_value\n",
    "from deel.lipdp.pipeline import load_and_prepare_data\n",
    "from deel.lipdp.sensitivity import get_max_epochs\n",
    "from deel.lipdp.model import DP_Accountant\n",
    "from deel.lipdp.model import DP_Sequential\n",
    "from deel.lipdp.model import DPParameters\n",
    "from deel.lipdp.model import AdaptiveLossGradientClipping"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data :\n",
    "\n",
    "It is important to import the data with the right DP parameters to account properly for the privacy guarantees of the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-06 17:15:23.533201: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-06 17:15:23.536683: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-06 17:15:23.536956: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-06 17:15:23.537554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-06 17:15:23.538489: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-06 17:15:23.538774: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-06 17:15:23.539067: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-06 17:15:23.859246: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-06 17:15:23.859540: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-06 17:15:23.859782: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-06 17:15:23.860009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8038 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "ds_train, ds_test, dataset_metadata = load_and_prepare_data(\n",
    "    \"mnist\",\n",
    "    batch_size=2048,\n",
    "    drop_remainder=True,  # accounting assumes fixed batch size\n",
    "    bound_fct=bound_clip_value(\n",
    "        10.0\n",
    "    ),  # clipping preprocessing allows to control input bound\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaring the DP parameters :\n",
    "\n",
    "We also need to declare explicitly the parameters of the DP training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_parameters = DPParameters(\n",
    "    noisify_strategy=\"global\",\n",
    "    noise_multiplier=1.5,\n",
    "    delta=1e-5,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the model :\n",
    "\n",
    "We use a simple convolutive network to classify on the MNIST dataset. We add a loss gradient clipping layer at the end of our network for more tightness on our gradient's upper bound. Therefore allowing for better results with one less hyperparameter to tune for dynamically chosen clipping constant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-06 17:15:24.564124: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.9/site-packages/deel/lip/model.py:74: UserWarning: Sequential model contains a layer which is not a 1-Lipschitz layer: dp__bounded_input\n",
      "  warn(_msg_not_lip.format(layer.name))\n",
      "/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.9/site-packages/deel/lip/model.py:74: UserWarning: Sequential model contains a layer which is not a 1-Lipschitz layer: dp__clip_gradient\n",
      "  warn(_msg_not_lip.format(layer.name))\n"
     ]
    }
   ],
   "source": [
    "layers = [\n",
    "    DP_layers.DP_BoundedInput(\n",
    "        input_shape=dataset_metadata.input_shape,\n",
    "        upper_bound=dataset_metadata.max_norm,\n",
    "    ),\n",
    "    DP_layers.DP_SpectralConv2D(filters=16, kernel_size=5),\n",
    "    DP_layers.DP_Flatten(),\n",
    "    DP_layers.DP_SpectralDense(units=10),\n",
    "    DP_layers.DP_ClipGradient(\n",
    "        epsilon=1, mode=\"dynamic_svt\", patience=10\n",
    "    )\n",
    "]\n",
    "\n",
    "model = DP_Sequential(\n",
    "    layers=layers, dp_parameters=dp_parameters, dataset_metadata=dataset_metadata\n",
    ")\n",
    "\n",
    "loss = DP_losses.DP_TauCategoricalCrossentropy(tau=14.0)\n",
    "\n",
    "# Compatible with any kind of non-private optimizer : \n",
    "opt = tf.keras.optimizers.SGD(learning_rate=1e-2)\n",
    "\n",
    "model.compile(\n",
    "    loss=loss,\n",
    "    optimizer=opt,\n",
    "    metrics=[\"accuracy\"],\n",
    "    run_eagerly=False,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the desired DP guarantees :\n",
    "\n",
    "We compute the budget of epochs needed to yields the DP guarantees that you desire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.9/site-packages/scipy/optimize/_optimize.py:2769: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  w = xb - ((xb - xc) * tmp2 - (xb - xa) * tmp1) / denom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch bounds = (0, 512.0) and epsilon = 57.32501154010554 at epoch 512.0\n",
      "epoch bounds = (0, 256.0) and epsilon = 33.19136621177765 at epoch 256.0\n",
      "epoch bounds = (0, 128.0) and epsilon = 18.700348347170372 at epoch 128.0\n",
      "epoch bounds = (0, 64.0) and epsilon = 11.0321546467658 at epoch 64.0\n",
      "epoch bounds = (0, 32.0) and epsilon = 6.628485024640014 at epoch 32.0\n",
      "epoch bounds = (0, 16.0) and epsilon = 3.656193225171896 at epoch 16.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch bounds = (8.0, 16.0) and epsilon = 1.9620813174159681 at epoch 8.0\n",
      "epoch bounds = (8.0, 12.0) and epsilon = 3.309417344453968 at epoch 12.0\n",
      "epoch bounds = (8.0, 10.0) and epsilon = 3.1263462214167053 at epoch 10.0\n",
      "epoch bounds = (9.0, 10.0) and epsilon = 2.0637926226770054 at epoch 9.0\n"
     ]
    }
   ],
   "source": [
    "num_epochs = get_max_epochs(3.0, model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model : \n",
    "\n",
    "The training process is called through the model.fit attribute. We use the following callbacks : \n",
    "\n",
    "- **DP_Accountant** (log_fn) : accounts for the privacy guarantees after each epoch of training (*log_fn* makes it compatible with W&B logging).\n",
    "- **DP_AdaptiveGradientClipping** (ds_train, patience) : automatically updates the losses's gradient clipping constant every *patience* steps. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On train begin : \n",
      "Initial value is now equal to lipschitz constant of loss:  tf.Tensor(1.4142135, shape=(), dtype=float32)\n",
      "Epoch 1/9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-06 17:15:27.779970: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/29 [=======================>......] - ETA: 0s - loss: 0.1282 - accuracy: 0.4295\n",
      " (0.8155744015343591, 1e-05)-DP guarantees for epoch 1 \n",
      "\n",
      "updated_clip_value :  0.9725372546049212\n",
      "29/29 [==============================] - 5s 63ms/step - loss: 0.1211 - accuracy: 0.4715 - val_loss: 0.0823 - val_accuracy: 0.6965\n",
      "Epoch 2/9\n",
      "25/29 [========================>.....] - ETA: 0s - loss: 0.0697 - accuracy: 0.7472\n",
      " (1.0133824304658074, 1e-05)-DP guarantees for epoch 2 \n",
      "\n",
      "29/29 [==============================] - 1s 15ms/step - loss: 0.0681 - accuracy: 0.7531 - val_loss: 0.0570 - val_accuracy: 0.7980\n",
      "Epoch 3/9\n",
      "25/29 [========================>.....] - ETA: 0s - loss: 0.0531 - accuracy: 0.8101\n",
      " (1.1872626615425608, 1e-05)-DP guarantees for epoch 3 \n",
      "\n",
      "29/29 [==============================] - 1s 14ms/step - loss: 0.0526 - accuracy: 0.8110 - val_loss: 0.0473 - val_accuracy: 0.8311\n",
      "Epoch 4/9\n",
      "25/29 [========================>.....] - ETA: 0s - loss: 0.0457 - accuracy: 0.8348\n",
      " (1.3410978829897524, 1e-05)-DP guarantees for epoch 4 \n",
      "\n",
      "29/29 [==============================] - 1s 14ms/step - loss: 0.0454 - accuracy: 0.8354 - val_loss: 0.0415 - val_accuracy: 0.8494\n",
      "Epoch 5/9\n",
      "25/29 [========================>.....] - ETA: 0s - loss: 0.0415 - accuracy: 0.8472\n",
      " (1.4829288251019426, 1e-05)-DP guarantees for epoch 5 \n",
      "\n",
      "29/29 [==============================] - 1s 14ms/step - loss: 0.0411 - accuracy: 0.8487 - val_loss: 0.0380 - val_accuracy: 0.8605\n",
      "Epoch 6/9\n",
      "25/29 [========================>.....] - ETA: 0s - loss: 0.0383 - accuracy: 0.8573\n",
      " (1.6162760206383275, 1e-05)-DP guarantees for epoch 6 \n",
      "\n",
      "29/29 [==============================] - 1s 14ms/step - loss: 0.0382 - accuracy: 0.8570 - val_loss: 0.0358 - val_accuracy: 0.8629\n",
      "Epoch 7/9\n",
      "25/29 [========================>.....] - ETA: 0s - loss: 0.0362 - accuracy: 0.8627\n",
      " (1.7358011312891797, 1e-05)-DP guarantees for epoch 7 \n",
      "\n",
      "29/29 [==============================] - 1s 13ms/step - loss: 0.0361 - accuracy: 0.8631 - val_loss: 0.0341 - val_accuracy: 0.8699\n",
      "Epoch 8/9\n",
      "25/29 [========================>.....] - ETA: 0s - loss: 0.0347 - accuracy: 0.8684\n",
      " (1.8526283446058953, 1e-05)-DP guarantees for epoch 8 \n",
      "\n",
      "29/29 [==============================] - 1s 14ms/step - loss: 0.0346 - accuracy: 0.8682 - val_loss: 0.0322 - val_accuracy: 0.8773\n",
      "Epoch 9/9\n",
      "25/29 [========================>.....] - ETA: 0s - loss: 0.0333 - accuracy: 0.8727\n",
      " (1.9620813174159681, 1e-05)-DP guarantees for epoch 9 \n",
      "\n",
      "29/29 [==============================] - 1s 14ms/step - loss: 0.0333 - accuracy: 0.8724 - val_loss: 0.0318 - val_accuracy: 0.8763\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    DP_Accountant(log_fn=\"logging\"),\n",
    "    AdaptiveLossGradientClipping(\n",
    "        ds_train=ds_train\n",
    "    ),  # DO NOT USE THIS CALLBACK WHEN mode != \"dynamic_svt\"\n",
    "]\n",
    "\n",
    "hist = model.fit(\n",
    "    ds_train,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=ds_test,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lipdp_dev_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
