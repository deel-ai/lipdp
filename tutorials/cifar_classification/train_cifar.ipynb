{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR CLASSIFICATION"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA 11.2 at /usr/local/cuda-11.2.\n",
      "Using CUDNN 8.1.0 at /usr/local/cudnn/11.2-v8.1.0\n"
     ]
    }
   ],
   "source": [
    "! set_cuda_version 11.2 8.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-03 10:24:29.493932: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-03 10:24:31.047789: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cudnn/11.0-v8.0.0/cuda/lib64:/usr/local/cuda-11.0/lib64\n",
      "2023-07-03 10:24:31.047842: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cudnn/11.0-v8.0.0/cuda/lib64:/usr/local/cuda-11.0/lib64\n",
      "2023-07-03 10:24:31.047848: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras_cv\n",
    "\n",
    "import deel.lipdp.layers as DP_layers\n",
    "import deel.lipdp.losses as DP_losses\n",
    "from deel.lipdp.pipeline import bound_clip_value\n",
    "from deel.lipdp.pipeline import load_and_prepare_data\n",
    "from deel.lipdp.sensitivity import get_max_epochs\n",
    "from deel.lipdp.model import DP_Accountant\n",
    "from deel.lipdp.model import DP_Sequential\n",
    "from deel.lipdp.model import DPParameters\n",
    "from deel.lipdp.model import AdaptiveLossGradientClipping"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data :\n",
    "\n",
    "It is important to import the data with the right DP parameters to account properly for the privacy guarantees of the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-03 10:24:35.878736: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-03 10:24:35.881609: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-03 10:24:35.881723: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-03 10:24:35.881990: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-03 10:24:35.882447: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-03 10:24:35.882574: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-03 10:24:35.882672: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-03 10:24:36.371226: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-03 10:24:36.371371: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-03 10:24:36.371470: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-03 10:24:36.371548: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6624 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "WARNING:tensorflow:From /home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "augmentations = [\n",
    "    keras_cv.layers.RandomRotation(0.2, fill_mode=\"reflect\", interpolation=\"bilinear\"),\n",
    "    keras_cv.layers.RandomTranslation(\n",
    "        0.2, 0.2, fill_mode=\"reflect\", interpolation=\"bilinear\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "ds_train, ds_test, dataset_metadata = load_and_prepare_data(\n",
    "    \"cifar10\",\n",
    "    batch_size=500,\n",
    "    colorspace=\"HSV\",\n",
    "    augmentations=augmentations,\n",
    "    drop_remainder=True,  # accounting assumes fixed batch size\n",
    "    bound_fct=bound_clip_value(\n",
    "        10.0\n",
    "    ),  # clipping preprocessing allows to control input bound\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please pay attention to the fact that the effective batch size in memory will be batch_size $\\times$ len(augmentations)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaring the DP parameters :\n",
    "\n",
    "We also need to declare explicitly the parameters of the DP training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_parameters = DPParameters(\n",
    "    noisify_strategy=\"global\",\n",
    "    noise_multiplier=2.0,\n",
    "    delta=1e-5,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the model :\n",
    "\n",
    "We use a simple convolutive network to classify on the MNIST dataset. We add a loss gradient clipping layer at the end of our network for more tightness on our gradient's upper bound. Therefore allowing for better results with one less hyperparameter to tune for dynamically chosen clipping constant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/deel/lip/model.py:74: UserWarning: Sequential model contains a layer which is not a 1-Lipschitz layer: dp__bounded_input\n",
      "  warn(_msg_not_lip.format(layer.name))\n",
      "/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/deel/lip/model.py:74: UserWarning: Sequential model contains a layer which is not a 1-Lipschitz layer: dp__clip_gradient\n",
      "  warn(_msg_not_lip.format(layer.name))\n"
     ]
    }
   ],
   "source": [
    "layers = [\n",
    "    DP_layers.DP_BoundedInput(\n",
    "        input_shape=dataset_metadata.input_shape,\n",
    "        upper_bound=dataset_metadata.max_norm,\n",
    "    ),\n",
    "    DP_layers.DP_SpectralConv2D(\n",
    "        filters=32, kernel_size=3, use_bias=False, kernel_initializer=\"orthogonal\"\n",
    "    ),\n",
    "    DP_layers.DP_Flatten(),\n",
    "    DP_layers.DP_SpectralDense(\n",
    "        units=512, use_bias=False, kernel_initializer=\"orthogonal\"\n",
    "    ),\n",
    "    DP_layers.DP_GroupSort(2),\n",
    "    DP_layers.DP_SpectralDense(\n",
    "        units=10, use_bias=False, kernel_initializer=\"orthogonal\"\n",
    "    ),\n",
    "    DP_layers.DP_ClipGradient(\n",
    "        epsilon=1, mode=\"dynamic_svt\", patience=5\n",
    "    )\n",
    "]\n",
    "\n",
    "model = DP_Sequential(\n",
    "    layers=layers, dp_parameters=dp_parameters, dataset_metadata=dataset_metadata\n",
    ")\n",
    "\n",
    "loss = DP_losses.DP_TauCategoricalCrossentropy(14.5)\n",
    "\n",
    "# Compatible with any kind of non-private optimizer : \n",
    "opt = tf.keras.optimizers.SGD(learning_rate=1e-2)\n",
    "\n",
    "model.compile(\n",
    "    loss=loss,\n",
    "    optimizer=opt,\n",
    "    metrics=[\"accuracy\"],\n",
    "    run_eagerly=False,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the desired DP guarantees :\n",
    "\n",
    "We compute the budget of epochs needed to yields the DP guarantees that you desire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/scipy/optimize/optimize.py:2621: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  w = xb - ((xb - xc) * tmp2 - (xb - xa) * tmp1) / denom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch bounds = (0, 512.0) and epsilon = 85.26272177783693 at epoch 512.0\n",
      "epoch bounds = (0, 256.0) and epsilon = 48.25957389491231 at epoch 256.0\n",
      "epoch bounds = (0, 128.0) and epsilon = 26.21744943567399 at epoch 128.0\n",
      "epoch bounds = (0, 64.0) and epsilon = 13.425955622771932 at epoch 64.0\n",
      "epoch bounds = (32.0, 64.0) and epsilon = 7.139827972307393 at epoch 32.0\n",
      "epoch bounds = (32.0, 48.0) and epsilon = 10.318302386220275 at epoch 48.0\n",
      "epoch bounds = (32.0, 40.0) and epsilon = 9.224465968334444 at epoch 40.0\n",
      "epoch bounds = (32.0, 36.0) and epsilon = 8.185134158355854 at epoch 36.0\n",
      "epoch bounds = (34.0, 36.0) and epsilon = 7.178060508347013 at epoch 34.0\n",
      "epoch bounds = (34.0, 35.0) and epsilon = 8.167545918253115 at epoch 35.0\n"
     ]
    }
   ],
   "source": [
    "num_epochs = get_max_epochs(8.0, model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model : \n",
    "\n",
    "The training process is called through the model.fit attribute. We use the following callbacks : \n",
    "\n",
    "- **DP_Accountant** (log_fn) : accounts for the privacy guarantees after each epoch of training (*log_fn* makes it compatible with W&B logging).\n",
    "- **DP_AdaptiveGradientClipping** (ds_train, patience) : automatically updates the losses's gradient clipping constant every *patience* steps. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On train begin : \n",
      "Initial value is now equal to lipschitz constant of loss:  tf.Tensor(1.4142135, shape=(), dtype=float32)\n",
      "Epoch 1/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-03 10:24:46.260843: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:421] Loaded runtime CuDNN library: 8.0.0 but source was compiled with: 8.1.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2023-07-03 10:24:46.261305: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at conv_ops.cc:1152 : UNIMPLEMENTED: DNN library is not found.\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node 'dp__sequential/dp__spectral_conv2d/convolution' defined at (most recent call last):\n    File \"/opt/miniconda/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/opt/miniconda/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/opt/miniconda/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/opt/miniconda/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/opt/miniconda/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 387, in do_execute\n      cell_id=cell_id,\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2976, in run_cell\n      raw_cell, store_history, silent, shell_futures, cell_id\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n      return runner(coro)\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3258, in run_cell_async\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_337893/3021743903.py\", line 12, in <module>\n      callbacks=callbacks,\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/deel/lipdp/model.py\", line 582, in train_step\n      y_pred = self(x, training=True)  # Forward pass\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/keras/engine/sequential.py\", line 413, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/deel/lip/layers.py\", line 551, in call\n      outputs = K.conv2d(\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/keras/backend.py\", line 6048, in conv2d\n      data_format=tf_data_format,\nNode: 'dp__sequential/dp__spectral_conv2d/convolution'\nDNN library is not found.\n\t [[{{node dp__sequential/dp__spectral_conv2d/convolution}}]] [Op:__inference_train_function_26698]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_337893/3021743903.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m )\n",
      "\u001b[0;32m~/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 53\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node 'dp__sequential/dp__spectral_conv2d/convolution' defined at (most recent call last):\n    File \"/opt/miniconda/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/opt/miniconda/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/opt/miniconda/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/opt/miniconda/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/opt/miniconda/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 387, in do_execute\n      cell_id=cell_id,\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2976, in run_cell\n      raw_cell, store_history, silent, shell_futures, cell_id\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n      return runner(coro)\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3258, in run_cell_async\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_337893/3021743903.py\", line 12, in <module>\n      callbacks=callbacks,\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/deel/lipdp/model.py\", line 582, in train_step\n      y_pred = self(x, training=True)  # Forward pass\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/keras/engine/sequential.py\", line 413, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/deel/lip/layers.py\", line 551, in call\n      outputs = K.conv2d(\n    File \"/home/thomas.massena/Code/DEBUG/dp-lipschitz/lipdp_dev_env/lib/python3.7/site-packages/keras/backend.py\", line 6048, in conv2d\n      data_format=tf_data_format,\nNode: 'dp__sequential/dp__spectral_conv2d/convolution'\nDNN library is not found.\n\t [[{{node dp__sequential/dp__spectral_conv2d/convolution}}]] [Op:__inference_train_function_26698]"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    DP_Accountant(log_fn=\"logging\"),\n",
    "    AdaptiveLossGradientClipping(\n",
    "        ds_train=ds_train\n",
    "    ),  # DO NOT USE THIS CALLBACK WHEN mode != \"dynamic_svt\"\n",
    "]\n",
    "\n",
    "hist = model.fit(\n",
    "    ds_train,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=ds_test,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lipdp_dev_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
